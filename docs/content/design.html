<h1>F# Data Frame design notes</h1>
<p>This is the first version of F# Data Frame library and so we are still actively looking
at how to improve the design. The best place for discussions is either the <a href="https://github.com/BlueMountainCapital/Deedle/issues">issue list
on GitHub</a> or the
mailing list of the <a href="http://fsharp.org/technical-groups/">F# for Data and Machine Learning</a>
group (for more broader topics).</p>
<p>The current version of the library implements most of the basic functionality,
but it hopefully provides the right "core" internals that should make it easier to add
all the additional (useful) features.</p>
<p>When developing the library, we follow the principle that there should be a small number
of <em>primitive</em> or <em>fundamental</em> functions (these are typically provided as members on
the basic objects) that can be used to provide a wide range of useful functions (typically
available as extension members and in F# modules). We are generally quite happy to include
more extension members and functions for commonly used operations, so feel free to contribute!</p>
<h2>Library principles</h2>
<ul>
<li>
<p><strong>F# and C# friendly</strong> - We want to make sure that the library works from both F# and C#.
For this reason, most functionality is exposed as extension members (using the C# <code>Extension</code>
attribute - so they are only visible in C# and F# 3.1) and as functions in modules
(<code>Frame</code> and <code>Series</code>). These are generally very similar. One difference is that functions
use tuples and F# <code>option&lt;T&gt;</code> and more abbreviations, while extensions use <code>KeyValuePair&lt;K, V&gt;</code>,
<code>OptionalValue&lt;T&gt;</code> (a C#-friendly <code>struct</code> defined in the library).</p>
</li>
<li>
<p><strong>Symmetry between rows and columns</strong> - The data in data frame is stored as a list of
columns and it is good idea to use the data frame in a column-wise way (and there are
more functions for working with column-based frames).</p>
<p>However, the data type <code>Frame&lt;'TRowKey, 'TColKey&gt;</code> is symmetric in that it uses custom
index for access by both columns (series) and rows. You can also access columns/rows as
a series of (nested) series via <code>df.Columns</code> and <code>df.Rows</code>. Although the column key is
typically going to be a string (series name), this is not required and you can e.g. transpose
frame using the <code>df.Transpose()</code> method.</p>
</li>
<li>
<p><strong>Missing and NaN values</strong> we assume that data frames can always contain missing values and
so there is no type distinction between frame/series that may have missing values and one
that may not have missing values. Operations available on the frame and series are designed
to handle missing values well - they generally skip over missing values unless you explicitly
try to read a value by a key.</p>
<p>The current version treats certain values as "missing" values, including <code>Double.NaN</code>
(for numeric values) and <code>null</code> (for <code>Nullable&lt;'T&gt;</code> types and reference types). This
means that when you create a series from <code>Double.NaN</code>, this is turned into a <em>missing</em> value
and the value is skipped when doing aggregation such as <code>Series.sum</code>. (An alternative would be
to support both <code>NaN</code> and <em>missing</em>, but there is no clear conclusion about what is the
most useful option.)</p>
</li>
<li>
<p><strong>Immutability</strong> - A series is fully immutable data type, but a
data frame supports limited mutation - you can add new series, drop a series &amp; replace
a series (but you cannot mutate the series). The row index of a data frame is mostly immutable -
the only case when it changes is when you create an empty data frame and than add the first
series.</p>
<p>This seems to be useful because it works nicely with the <code>?&lt;-</code> operator and you do not have
to re-bind when you're writing some research script.</p>
</li>
</ul>
<h2>Library internals</h2>
<p>The Deedle implementation uses two layers. In the public API, you work with series and frames.
Under the cover, all of the operations are provided by indices (providng lookup and alignment)
and vectors (providing data storage). These are implemented in multiple different ways - most
notably, Deedle supports in-memory version and <a href="bigdeedle.html">BigDeedle provides virtualised
implementation</a> that can be used for big time series without fully loading it
into memory.</p>
<h3>Vectors and indices</h3>
<p>The following types are (mostly) not directly visible to the user, but they represent the
"minimal" core that changes infrequently. You could use them when extending the library:</p>
<ul>
<li>
<p><code>IVector&lt;'TValue&gt;</code> represents a vector (essentially an abstract data
storage) that contains values <code>'TValue</code> that can be accessed via an address
<code>Address</code>. A simple concrete implementation is an array with <code>int</code> addresses,
but we aim to make this abstract - one could use an array of arrays with <code>int64</code>
index for large data sets, lazy vector that loads data from a stream or even
a virtual vector with e.g. Cassandra data source).</p>
<p>An important thing about vectors is that they handle missing values, so vector
of integers is actually more like <code>array&lt;option&lt;int&gt;&gt;</code> (but we have a custom value
type so that this is continuous block of memory). We decided that handling missing
values is something that is so important for data frame, that it should be directly
supported rather than done by e.g. storing optional or nullable values. Our
implementation actually does a simple optimization - if there are no missing values,
it just stores <code>array&lt;int&gt;</code>.</p>
</li>
<li>
<p><code>VectorConstruction</code> is a discriminated union (DSL) that describes
construction of vector. For every vector type, there is an <code>IVectorBuilder</code>
that knows how to construct vectors using the construction instructions (these
include things like re-shuffling of elements, appending vectors, getting a sub-range
etc.)</p>
</li>
<li>
<p><code>IIndex&lt;'TKey&gt;</code> represents an index - that is, a mapping from keys
of a series or data frame to addresses in a vector. In the simple case, this is just
a hash table that returns the <code>int</code> offset in an array when given a key (e.g.
<code>string</code> or <code>DateTime</code>). A super-simple index would just map <code>int</code> offsets to
<code>int</code> addresses via an identity function (not implemented yet!) - if you have
series or data frame that is simply a list of recrods.</p>
</li>
</ul>
<h3>Series and frames</h3>
<p>The following types are the public API, wrapping the vectors and indices:</p>
<ul>
<li>
<p><code>Series&lt;'TKey, 'TValue&gt;</code> represents a series of values <code>'TValue</code> indexed by an
index <code>'TKey</code>. A series uses an abstract vector, index and vector builder, so it
should work with any data representation. A series provides some standard slicing
operators, projection, filtering etc. There are also some binary operators (multiply
by a scalar, add series, etc.) and addtional operations in the <code>Series</code> module.</p>
</li>
<li>
<p><code>Frame&lt;'TRowKey, 'TColumnKey&gt;</code> represents a data frame with rows indexed using
<code>TRowKey</code> (this could be <code>DateTime</code> or just ordinal numbers like <code>int</code>) and columns
indexed by <code>TColumnKey</code> (typically a <code>string</code>). The data in the frame can be
hetrogeneous (e.g. different types of values in different columns) and so accessing
data is dynamic - but you can e.g. get a typed series.</p>
<p>The operations available on the data frame include adding &amp; removing series (which
aligns the new series according to the row index), joins (again - aligns the series)
etc. You can also get all rows as a series of (column) series and all columns as a
series of (row) series - they are available as extension methods and in the <code>Frame</code> module.</p>
</li>
</ul>
<h3>Vector builders and index builders</h3>
<p>The indices and vectors are constructed using <code>IIndexBuilder</code> and <code>IVectorBuilder</code>. Typically,
index builder creates a new index and returns a <code>VectorConstruction</code> that can then be passed
to <code>IVectorBuilder.Build</code> to perform the corresponding transformation on all vectors
(for example, transform all vectors of a data frame according to an operation applied to the
index).</p>
<p>Indices and vectors are connected via an address. Addresses are represented by the <code>Address</code>
type and they are used to map keys (of the index) to values (in the vector). Here is a brief
summary of what we assume (and don't assume) about addresses:</p>
<ul>
<li>Address is <code>int64</code> (although we might need to generalize this in the future)</li>
<li>
Different data sources can use different addressing schemes
(as long as both index and vector use the same scheme)
</li>
<li>
Addresses don't have to be continuous (e.g. if the source is partitioned, it
can use 32bit partition index + 32bit offset in the partition)
</li>
<li>In the in-memory representation, address is just index into an array</li>
<li>
In the BigDeedle representation, address is abstracted and comes with
<code>AddressOperations</code> that specifies how to use it (tests use linear
offset and partitioned representation)
</li>
</ul>
<p>To capture the different options, Deedle has an interface called <code>IAddressingScheme</code>.
This represents the addressing mode used (it has no methods - it is just an object
that can be compared). Vectors and indices both expose <code>AddressingScheme</code> property
that can be used to check that their addressing schemes match.</p>
<p>Whenever we have index and vector, we need to make sure that they share the same
addressing scheme. There is a number of things that ensure this:</p>
<ul>
<li>
<p>Series and frames keep an <code>IIndexBuilder</code> and a <code>IVectorBuilder</code> to be used for
performing operations with the internal structures. These should always match, i.e.
they should produce indices/vectors with the same addressing scheme.</p>
</li>
<li>
<p><code>IIndexBuilder</code> may not be able to perform all operations without fully materializing
the index (e.g. BigDeedle can only do some operations). In that case, it returns
an index with different addressing scheme. When calling <code>IVectorBuilder.Build</code>,
this takes <code>VectorConstruction</code> together with <code>IAddressingScheme</code> and so it can
ensure that the created vector has the correct addressing scheme (i.e. if the
required addressing scheme is linear, partitioned virtual index can materialize
the vector before returning it).</p>
</li>
<li>
<p><code>IVector</code> can also materialize vectors (when using <code>Select</code> or <code>Convert</code> methods). When
those are called, the caller should apply <code>IIndexBuilder.Project</code> on the index, which
performs the corresponding materialization on the index.</p>
</li>
<li>
<p>When the calling code creates a new index or vector directly (typically in-memory
index/vector calculated from keys or values), it needs to make sure that the other structure
matches too. When a new vector is created using <code>IVectorBuilder.Create</code>,
the index needs to be transformed using <code>IIndexBuilder.Recreate</code>.</p>
</li>
</ul>
<h2>BigDeedle and virtual series and frames</h2>
<p>The "BigDeedle" project implements virtualized data sources that can perform many operations
of Deedle without actually evaluating the data. This consists of <code>VirtualVector&lt;'T&gt;</code> and
<code>VirtualOrderedIndex&lt;'T&gt;</code> and <code>VirtualOrdinalIndex&lt;'T&gt;</code> (there are two indices - one for
ordinal keys and one for user-specified keys) together with their builders.</p>
<p>BigDeedle is extensible and you only need to provide fairly small number of operations to
use it. The interfaces to look at are:</p>
<ul>
<li>
<code>IVirtualVectorSource&lt;'T&gt;</code> where <code>'T</code> is the type of values of the source. This interface
is used as a source for both virtual vectors (data access) and virtual indices (keys).
Once you have a value of this, you can use <code>Virtual.CreateSeries</code> and similar methods
to build a series or a frame.
</li>
</ul>
<p>The most tricky thing of the implementation is often <code>IAddressOperations</code>:</p>
<ul>
<li>
<p>If you already have some underlying infrastructure that handles merging and slicing of
virtual sources, then you can implement the interface directly on top of this (and
use the infrastructure in merging and slicing operations of <code>IVirtualVectorSource</code>).</p>
</li>
<li>
<p>More frequently, you'll want to use the <code>Ranges&lt;'K&gt;</code> type provided by Deedle. This
represents a mapping from some keys <code>'K</code> to offsets and it supports merging and slicing
(so you do not have to write your own code to merge slices of virtual soruces).
To use this, you can use <code>RangesAddressOperations(...)</code> which gives you an implementation
of <code>IAddressOperations</code>. For a reasonably simple example, see the code in
<a href="https://github.com/tpetricek/Deedle/blob/big-deedle-addr/tests/Deedle.Tests/VirtualPartitioned.fs">tests using partitioned addressing scheme</a>.</p>
</li>
</ul>
<h2>Discussion and open questions</h2>
<p>We're hoping that the design of the internals is now reasonable, but the end user API may
still be missing some useful functionality (let us know if you need some!) Here are a few
things that we discussed earlier and that we may still look into at some point:</p>
<ul>
<li>
<p><strong>Time series vs. pivot table</strong> - there is some mismatch between two possible
interpretations and uses of the library. One is for time-series data (e.g. in finance)
where one typically works with dates as row indices. More generally, you can see this
as <em>continous</em> index. It makes sense to do interpolation, sort the observations,
align them, re-scale them etc. (Note that <em>continuous</em> is stronger than <em>ordered</em> -
aside from time, the only continuous measure we can think of is distance-dependent
series.)</p>
<p>The other case is when we have some <em>discrete</em> observations (perhaps a list of
records with customer data, a list of prices of different stock prices etc.) In this
case, we need more "pivot table" functions etc.</p>
<p>Although these two uses are quite different, we feel that it might make sense to use
the same type for both (just with a different index). The problem is that this might
make the API more complex. Although, if we can keep the distincion in the type, we can
use F# 3.1 extension methods that extend just "discrete data frame" or "continous data
frame". However, for now all functions are available in <code>Frame</code>/<code>Series</code> module and
as extension methods that extend any type.</p>
</li>
<li>
<p><strong>Type provider</strong> - we are thinking about using type providers to give some additional
safety (like checking column names and types in a data frame). This is currently
on the TODO list - we think we can do something useful here, although it will
certainly be limited.</p>
<p>The current idea is that you migth want to do some research/prototyping using a
dynamic data frame, but once you're done and have some more stable data, you should
be able to write, say <code>DataFrame&lt;"Open:float,Close:float"&gt;(dynamicDf)</code> and get a
new typed data frame.</p>
</li>
</ul>
<p>If you have any comments regarding the topics above, please <a href="https://github.com/BlueMountainCapital/Deedle/issues">submit an issue
on GitHub</a> or, if you
are interested in more actively contributing, join
the <a href="http://fsharp.org/technical-groups/">F# for Data and Machine Learning</a> working
group.</p>


